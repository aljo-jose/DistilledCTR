{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "# load data samples\n",
    "# feed and get weights at observation level.\n",
    "# get features from feature mapper\n",
    "# interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import distilled_ctr.model.nam as nam\n",
    "from distilled_ctr.dataset.avazu import AvazuDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'avazu'\n",
    "dataset_path = '../data/avazu/small'\n",
    "dataset = AvazuDataset(dataset_path,cache_path='../.avazu', rebuild_cache=False)\n",
    "cache = dataset.cache\n",
    "field_dims = dataset.field_dims\n",
    "feature_mapper = dataset.feat_mapper\n",
    "\n",
    "features = ['hour','C1','banner_pos','site_id','site_domain','site_category',\n",
    "'app_id','app_domain','app_category','device_id','device_ip','device_model',\n",
    "'device_type','device_conn_type','C14','C15','C16','C17','C18','C19','C20','C21']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   1   1  18  75   2  20   2   5   0  45 215   0   1   5   0   2\n",
      "  16   1   6  14  16]\n",
      "[  2   5   3  86  78  11  47  17   9   7  73 216   5   5  98   4   4  73\n",
      "   5  27  49  24]\n",
      "22\n",
      "{'1007': 0, '1005': 1, '1010': 2, '1002': 3}\n"
     ]
    }
   ],
   "source": [
    "print(cache[0])\n",
    "print(field_dims)\n",
    "print(len(feature_mapper))\n",
    "print(feature_mapper[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = '../chkpt/avazu_nam.pt'\n",
    "embed_dim = 16\n",
    "model = nam.NeuralAdditiveModel(\n",
    "    input_size=len(field_dims),\n",
    "    field_dims=field_dims,\n",
    "    embed_dim=embed_dim,\n",
    "    shallow_units=embed_dim,\n",
    "    hidden_units=list(map(int, [])),\n",
    "    shallow_layer=nam.ExULayer,\n",
    "    hidden_layer=nam.ExULayer,\n",
    "    hidden_dropout=0,\n",
    "    feature_dropout=0\n",
    ")\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   1,  64,  33,   6,  46,  16,   7,   6,  72, 215,   0,\n",
      "          1,  50,   0,   2,   9,   2,  25,  18,  11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.2461], grad_fn=<SigmoidBackward>), tensor(0))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1770\n",
    "record = torch.tensor(cache[index], dtype=torch.long)\n",
    "x,target = record[1:], record[0]\n",
    "print(record)\n",
    "p = model(x)\n",
    "p, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770\n",
      "[  0   0   0   1  64  33   6  46  16   7   6  72 215   0   1  50   0   2\n",
      "   9   2  25  18  11]\n"
     ]
    }
   ],
   "source": [
    "# for i,rec in enumerate(cache):\n",
    "#     if rec[2] == 0:\n",
    "#         print(i)\n",
    "#         print(rec)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour : 0.36594945192337036\n",
      "C1 : 0.38024839758872986\n",
      "banner_pos : 0.4000239670276642\n",
      "site_id : 0.5\n",
      "site_domain : 0.48257145285606384\n",
      "site_category : 0.4371621310710907\n",
      "app_id : 0.5\n",
      "app_domain : 0.35416099429130554\n",
      "app_category : 0.42346879839897156\n",
      "device_id : 0.6363614797592163\n",
      "device_ip : 0.2787962555885315\n",
      "device_model : 0.8083107471466064\n",
      "device_type : 0.5\n",
      "device_conn_type : 0.6672606468200684\n",
      "C14 : 0.0058508808724582195\n",
      "C15 : 0.5\n",
      "C16 : 0.3814810514450073\n",
      "C17 : 0.6049033999443054\n",
      "C18 : 0.5\n",
      "C19 : 0.5333901047706604\n",
      "C20 : 0.815177857875824\n",
      "C21 : 0.967589795589447\n"
     ]
    }
   ],
   "source": [
    "weights = model.get_observation_weights(x).tolist()\n",
    "weights\n",
    "for feature,weight in zip(features,weights):\n",
    "    print(f'{feature} : {weight}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature contributions at global level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1007': 0, '1005': 1, '1010': 2, '1002': 3}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_index = 2\n",
    "feature_mapper[feature_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3802]],\n",
       "\n",
       "        [[0.3700]],\n",
       "\n",
       "        [[0.2536]],\n",
       "\n",
       "        [[0.2536]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_indices = np.array(list(feature_mapper[feature_index].values()))\n",
    "embed_indices = feature_indices + model.embedding.offsets[feature_index-1]\n",
    "embed_indices = torch.tensor(embed_indices, dtype=torch.long)\n",
    "x = model.embedding.embedding(embed_indices)\n",
    "fnn_out = model.feature_nns[feature_index-1](x)\n",
    "feature_weights = torch.sigmoid(fnn_out)\n",
    "feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1007': 0, '1005': 1, '1010': 2, '1002': 3}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mapper[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
